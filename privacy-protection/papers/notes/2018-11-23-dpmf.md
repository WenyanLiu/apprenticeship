# DPMF

> **Title**: Differentially Private Matrix Factorization

> **Authors**: Jingyu Hua, Chang Xia, Sheng Zhong

> **Institution**: State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, China

> **Conference**: International Joint Conference on Artificial Intelligence (IJCAI)

> **Year**: 2015

### Topic

Differential privacy; Matrix factorization

### Motivation

Recommendation systems (RSes) provide users personalized recommendations of contents and services. To offer useful recommendations, a RS usually requires users to supply their personal preferences for various items, which raises serious privacy concerns.

Is it possible to build a recommendation system without the recommender learning the users’ ratings of items?

### Approach

A differentially private MF mechanism guarantees that the execution of the learning algorithm exposes only item profile matrix, i.e., <img src="https://latex.codecogs.com/gif.latex?V" title="V" /> to the untrusted recommender but never any information about users’ ratings or even <img src="https://latex.codecogs.com/gif.latex?U" title="U" />.

**Scenario 1**:

The recommender is trusted.

*Hypothesis*: The recommender has collected the ratings of users and wants to learn and publish the final item profile matrix <img src="https://latex.codecogs.com/gif.latex?V" title="V" /> satisfying <img src="https://latex.codecogs.com/gif.latex?\epsilon" title="\epsilon" />-differential privacy.

*Idea*: Achieve differential privacy by randomly perturbing the objective function instead of perturbing the output of the leaning algorithm.

- The recommender performs the original RLSM.

- The recommender uses the obtained <img src="https://latex.codecogs.com/gif.latex?U" title="U" /> as a constant profile matrix when minimize the objective.

**Scenario 2**:

The recommender is untrusted but the online users are static

*Challenge*:

- How the <img src="https://latex.codecogs.com/gif.latex?k" title="k" /> users can independently select <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j^{i_s}" title="\eta _j^{i_s}" /> such that the resulting sum <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j" title="\eta _j" /> follows the distribution of <img src="https://latex.codecogs.com/gif.latex?p(\eta&space;_j)\propto&space;e^{-\frac{\epsilon&space;\left&space;\|&space;\eta&space;_j&space;\right&space;\|}{2\Delta&space;}}" title="p(\eta _j)\propto e^{-\frac{\epsilon \left \| \eta _j \right \|}{2\Delta }}" />?

- Difference attack?

*Idea*:

- The recommender picks a random number vector <img src="https://latex.codecogs.com/gif.latex?H_j" title="H_j" />, of which each element <img src="https://latex.codecogs.com/gif.latex?H_j\left&space;[&space;l&space;\right&space;]\sim&space;Exponential(1)" title="H_j\left [ l \right ]\sim Exponential(1)" />, and sends it to every user in <img src="https://latex.codecogs.com/gif.latex?User_j" title="User_j" />.
User <img src="https://latex.codecogs.com/gif.latex?i_s" title="i_s" /> independently selects a random vector <img src="https://latex.codecogs.com/gif.latex?C_{i_s}" title="C_{i_s}" />, which each element <img src="https://latex.codecogs.com/gif.latex?C_{i_s}\left&space;[&space;l&space;\right&space;]\sim&space;N(0,&space;\frac{1}{k})" title="C_{i_s}\left [ l \right ]\sim N(0, \frac{1}{k})" /> and computes <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j^{i_s}" title="\eta _j^{i_s}" /> according to <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j^{i_s}\left&space;[&space;l&space;\right&space;]=\frac{2\Delta&space;\sqrt{d}}{\epsilon&space;}\cdot&space;\sqrt{2H_j\left&space;[&space;l&space;\right&space;]}C_{i_s}\left&space;[&space;l&space;\right&space;]" title="\eta _j^{i_s}\left [ l \right ]=\frac{2\Delta \sqrt{d}}{\epsilon }\cdot \sqrt{2H_j\left [ l \right ]}C_{i_s}\left [ l \right ]" />.

- When user <img src="https://latex.codecogs.com/gif.latex?i_s" title="i_s" /> requests <img src="https://latex.codecogs.com/gif.latex?v_j(t)" title="v_j(t)" /> from the recommender in the beginning of the <img src="https://latex.codecogs.com/gif.latex?t" title="t" />-th iteration, the server generates a random noise vector <img src="https://latex.codecogs.com/gif.latex?\Psi&space;_j^{i_s}(t)" title="\Psi _j^{i_s}(t)" />, of which the elements are i.i.d. on <img src="https://latex.codecogs.com/gif.latex?[0,p]" title="[0,p]" />.
It returns <img src="https://latex.codecogs.com/gif.latex?\Psi&space;_j^{i_s}(t)" title="\Psi _j^{i_s}(t)" /> together with <img src="https://latex.codecogs.com/gif.latex?v_j(t)" title="v_j(t)" /> to user <img src="https://latex.codecogs.com/gif.latex?i_s" title="i_s" />.

- User <img src="https://latex.codecogs.com/gif.latex?i_s" title="i_s" /> computes <img src="https://latex.codecogs.com/gif.latex?\widetilde{\triangledown&space;}_{v_j}^{i_s}(t)=\triangledown&space;_{v_j}^{i_s}(t)&plus;\eta&space;_j^{i_s}&plus;\widetilde{\rho}&space;_j^{i_s}(t)" title="\widetilde{\triangledown }_{v_j}^{i_s}(t)=\triangledown _{v_j}^{i_s}(t)+\eta _j^{i_s}+\widetilde{\rho} _j^{i_s}(t)" />.
The user computes <img src="https://latex.codecogs.com/gif.latex?\Phi&space;_j^{i_s}(t)=\widetilde{\triangledown&space;}_{v_j}^{i_s}(t)&plus;\Psi&space;_j^{i_s}(t)\&space;mod\&space;P" title="\Phi _j^{i_s}(t)=\widetilde{\triangledown }_{v_j}^{i_s}(t)+\Psi _j^{i_s}(t)\ mod\ P" />, and forwards it to the third-party.

- The third-party aggregates the results from users in <img src="https://latex.codecogs.com/gif.latex?User_j" title="User_j" /> and computes <img src="https://latex.codecogs.com/gif.latex?\Phi&space;_j(t)=\sum&space;_{s=1}^k&space;\Phi&space;_j^{i_s}(t)\&space;mod\&space;P" title="\Phi _j(t)=\sum _{s=1}^k \Phi _j^{i_s}(t)\ mod\ P" />.
The result is forwarded to the recommender.

- The recommender computes <img src="https://latex.codecogs.com/gif.latex?\widetilde{\triangledown&space;}_{v_j}(t)=\Phi&space;_j(t)-\sum&space;_{s=1}^k&space;\Psi&space;_j^{i_s}(t)\&space;mod\&space;P" title="\widetilde{\triangledown }_{v_j}(t)=\Phi _j(t)-\sum _{s=1}^k \Psi _j^{i_s}(t)\ mod\ P" />, and uses it to update <img src="https://latex.codecogs.com/gif.latex?v_j(t)" title="v_j(t)" />.

**Scenario 3**:

The recommender is untrusted and the online users are dynamic

*Challenge*: Different groups of users produce random variables with the same sum?

*Idea*:

- The recommender randomly picks <img src="https://latex.codecogs.com/gif.latex?k" title="k" /> online users, i.e., <img src="https://latex.codecogs.com/gif.latex?UO=\left&space;\{&space;u_{i_1},u_{i_2},...,u_{i_k}&space;\right&space;\}" title="UO=\left \{ u_{i_1},u_{i_2},...,u_{i_k} \right \}" />, and sends each <img src="https://latex.codecogs.com/gif.latex?u_{i_s}\in&space;UO" title="u_{i_s}\in UO" /> a random vector <img src="https://latex.codecogs.com/gif.latex?\beta&space;_j^{i_s}" title="\beta _j^{i_s}" />, of which the elements are i.i.d. on <img src="https://latex.codecogs.com/gif.latex?[0,P]" title="[0,P]" />.

- User <img src="https://latex.codecogs.com/gif.latex?u_{i_s}" title="u_{i_s}" /> picks the local noise vector <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j^{i_s}" title="\eta _j^{i_s}" /> the same as before, and computes <img src="https://latex.codecogs.com/gif.latex?\tau&space;_j^{i_s}=\eta&space;_j^{i_s}&plus;\beta&space;_j^{i_s}\&space;mod\&space;P" title="\tau _j^{i_s}=\eta _j^{i_s}+\beta _j^{i_s}\ mod\ P" />.
The result is forwarded to the third-party.

- The third-party aggregates the results from each user and computes <img src="https://latex.codecogs.com/gif.latex?\widetilde{\tau&space;}_j=\alpha&space;_j&plus;\sum&space;_{s=1}^k&space;\tau&space;_j^{i_s}\&space;mod\&space;P" title="\widetilde{\tau }_j=\alpha _j+\sum _{s=1}^k \tau _j^{i_s}\ mod\ P" />, where <img src="https://latex.codecogs.com/gif.latex?\alpha&space;_j" title="\alpha _j" /> is another random vector, of which the elements are i.i.d. on <img src="https://latex.codecogs.com/gif.latex?[0,P]" title="[0,P]" />. 
The result is sent to the recommender.

- The recommender derives <img src="https://latex.codecogs.com/gif.latex?\widehat{\tau&space;}_j=\alpha&space;_j&plus;\sum&space;_{s=1}^k&space;\eta&space;_j^{i_s}\&space;mod\&space;P" title="\widehat{\tau }_j=\alpha _j+\sum _{s=1}^k \eta _j^{i_s}\ mod\ P" /> by removing each <img src="https://latex.codecogs.com/gif.latex?\beta&space;_j^{i_s}" title="\beta _j^{i_s}" />, and keeps it secret.



- The recommender randomly divides <img src="https://latex.codecogs.com/gif.latex?\widehat{\tau&space;}_j" title="\widehat{\tau }_j" /> into <img src="https://latex.codecogs.com/gif.latex?{k}'" title="{k}'" /> pieces, and sends every user <img src="https://latex.codecogs.com/gif.latex?u_{i_s}" title="u_{i_s}" /> in this group a piece <img src="https://latex.codecogs.com/gif.latex?\widehat{\tau&space;}_j^{i_s}" title="\widehat{\tau }_j^{i_s}" />.

- User <img src="https://latex.codecogs.com/gif.latex?u_{i_s}" title="u_{i_s}" /> uses <img src="https://latex.codecogs.com/gif.latex?\widehat{\tau&space;}_j^{i_s}" title="\widehat{\tau }_j^{i_s}" /> to replace <img src="https://latex.codecogs.com/gif.latex?\eta&space;_j^{i_s}" title="\eta _j^{i_s}" />.

- The third-party minuses <img src="https://latex.codecogs.com/gif.latex?\alpha&space;_j" title="\alpha _j" /> from <img src="https://latex.codecogs.com/gif.latex?\Phi&space;_j(t)" title="\Phi _j(t)" /> before uploading.

### Contribution

- Figure out the required distribution of the noise component for objective perturbation in MF;

- Decompose the noise component for objective perturbation into small pieces that can be determined locally and independently by users;

- A third-party based mechanism to reduce noises added in each iteration.

### Performance

**Dataset**:

- Netflix dataset (191668 users' ratings of 100 movies, 5 star range)

- MovieLens 100k (943 users' ratings of 1682 movies, 5 star range)

**Baseline**:

PMF

**Metric**:

Accuracy

- The cumulative distribution function (CDF) of prediction errors

- The mean increase of prediction errors compared with the baseline
Communication overheads
